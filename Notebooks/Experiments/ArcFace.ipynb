{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1️⃣ Install dependencies\n",
        "# ============================================\n",
        "!pip install -q insightface onnxruntime-gpu scikit-learn tqdm opencv-python-headless\n",
        "\n",
        "import os, glob, cv2, numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from insightface.app import FaceAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OGYTmZ6XPWQ",
        "outputId": "5a466f81-2d2b-452c-ca96-765acdfbd5c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m430.1/439.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.5/300.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 2️⃣ Mount Google Drive\n",
        "# ============================================\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "drive_base = \"/content/drive/MyDrive/FER2013_images\"\n",
        "os.makedirs(drive_base, exist_ok=True)\n",
        "\n",
        "# Embeddings file paths\n",
        "train_embeddings_file = os.path.join(drive_base, \"arcface_train_embeddings.npz\")\n",
        "test_embeddings_file  = os.path.join(drive_base, \"arcface_test_embeddings.npz\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2HtTHUBXPT7",
        "outputId": "6cba2695-754b-44a8-c29a-d5bbefa317ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"{drive_base}/train\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPijoByxiuwc",
        "outputId": "f52e9316-3111-4ea6-e76e-e868d1e490d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "angry  disgust\tfear  happy  neutral  sad  surprise\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3️⃣ Collect image paths and labels from train/test\n",
        "# ============================================\n",
        "emotion_map = {\n",
        "    'angry': 0,\n",
        "    'disgust': 1,\n",
        "    'fear': 2,\n",
        "    'happy': 3,\n",
        "    'sad': 4,\n",
        "    'surprise': 5,\n",
        "    'neutral': 6\n",
        "}\n",
        "\n",
        "train_paths = glob.glob(os.path.join(drive_base, \"train\", \"*\", \"*.jpg\"), recursive=True)\n",
        "test_paths  = glob.glob(os.path.join(drive_base, \"test\", \"*\", \"*.jpg\"), recursive=True)\n",
        "\n",
        "train_labels = [emotion_map[os.path.basename(os.path.dirname(p))] for p in train_paths]\n",
        "test_labels  = [emotion_map[os.path.basename(os.path.dirname(p))] for p in test_paths]\n",
        "\n",
        "print(f\"✅ Train images: {len(train_paths)}, Test images: {len(test_paths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca9EQ2F_XPRk",
        "outputId": "755a47ef-d284-4626-bc41-f18ade1550a5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train images: 28709, Test images: 7178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Automatically loads final embeddings → skips extraction if already done.\n",
        "2) Resumes from partial chunks → no wasted computation if interrupted.\n",
        "3) Saves in chunks → safe for overnight Colab runs.\n",
        "4) Optional CLAHE toggle → faster extraction if disabled."
      ],
      "metadata": {
        "id": "eggbT2T9oO0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4️⃣ Embedding extraction (resumable)\n",
        "# ============================================\n",
        "def extract_embeddings(image_paths, labels, embeddings_file, chunk_size=5000, use_CLAHE=False):\n",
        "    \"\"\"\n",
        "    Smart embedding extraction for Buffalo-S:\n",
        "    - Loads final embeddings if they exist\n",
        "    - Resumes from partial embeddings if available\n",
        "    - Saves in chunks to prevent data loss\n",
        "    \"\"\"\n",
        "    # 1️⃣ Load final embeddings if already present\n",
        "    if os.path.exists(embeddings_file):\n",
        "        print(f\"📥 Final embeddings found. Loading from {embeddings_file}...\")\n",
        "        data = np.load(embeddings_file)\n",
        "        return data['X'], data['y']\n",
        "\n",
        "    embeddings, y_list = [], []\n",
        "    start_idx = 0\n",
        "\n",
        "    # 2️⃣ Check for partial embeddings\n",
        "    dir_path = os.path.dirname(embeddings_file)\n",
        "    if os.path.exists(dir_path):\n",
        "        partial_files = sorted([f for f in os.listdir(dir_path) if f.startswith(\"partial_\")])\n",
        "        if partial_files:\n",
        "            last_file = partial_files[-1]\n",
        "            print(f\"📥 Resuming from partial embeddings: {last_file}\")\n",
        "            data = np.load(os.path.join(dir_path, last_file))\n",
        "            embeddings.extend(data['X'])\n",
        "            y_list.extend(data['y'])\n",
        "            start_idx = int(last_file.split(\"_\")[-1].split(\".\")[0])  # last index\n",
        "\n",
        "    # 3️⃣ Initialize Buffalo-S\n",
        "    app = FaceAnalysis(name=\"buffalo_s\", root=\"./\", providers=['CUDAExecutionProvider'])\n",
        "    app.prepare(ctx_id=0, det_size=(224, 224))\n",
        "    print(\"✅ Buffalo-S FaceAnalysis loaded.\")\n",
        "\n",
        "    def apply_CLAHE(img):\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        l, a, b = cv2.split(lab)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        cl = clahe.apply(l)\n",
        "        merged = cv2.merge((cl,a,b))\n",
        "        return cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # 4️⃣ Process images\n",
        "    for i in tqdm(range(start_idx, len(image_paths)), desc=\"Extracting embeddings\"):\n",
        "        img = cv2.imread(image_paths[i])\n",
        "        if img is None:\n",
        "            continue\n",
        "        if use_CLAHE:\n",
        "            img = apply_CLAHE(img)\n",
        "        faces = app.get(img)\n",
        "        if len(faces) == 0:\n",
        "            continue\n",
        "        emb = faces[0]['embedding']\n",
        "        emb /= np.linalg.norm(emb)\n",
        "        embeddings.append(emb)\n",
        "        y_list.append(labels[i])\n",
        "\n",
        "        # Save partial chunk\n",
        "        if (i+1) % chunk_size == 0:\n",
        "            partial_file = os.path.join(dir_path, f\"partial_{i+1}.npz\")\n",
        "            np.savez(partial_file, X=np.array(embeddings), y=np.array(y_list))\n",
        "            print(f\"💾 Saved partial embeddings up to image {i+1} → {partial_file}\")\n",
        "\n",
        "    # 5️⃣ Save final embeddings\n",
        "    X = np.array(embeddings)\n",
        "    y = np.array(y_list)\n",
        "    np.savez(embeddings_file, X=X, y=y)\n",
        "    print(f\"✅ Saved final embeddings to {embeddings_file} ({len(X)} samples)\")\n",
        "\n",
        "    # Optional: remove old partials\n",
        "    if 'partial_files' in locals():\n",
        "        for f in partial_files:\n",
        "            os.remove(os.path.join(dir_path, f))\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "nnYkXYCNXWRe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5️⃣ Extract or load embeddings\n",
        "# ============================================\n",
        "X_train, y_train = extract_embeddings(train_paths, train_labels, train_embeddings_file)\n",
        "X_test,  y_test  = extract_embeddings(test_paths, test_labels,  test_embeddings_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NntVVOCkXZUP",
        "outputId": "d9a79e40-c28f-4479-f47f-6dcf348e91a4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (224, 224)\n",
            "✅ Buffalo-S FaceAnalysis loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings:  17%|█▋        | 5000/28709 [29:19<3:16:08,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved partial embeddings up to image 5000 → /content/drive/MyDrive/FER2013_images/partial_5000.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings:  35%|███▍      | 10000/28709 [1:08:28<2:04:48,  2.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved partial embeddings up to image 10000 → /content/drive/MyDrive/FER2013_images/partial_10000.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings:  52%|█████▏    | 15000/28709 [1:46:48<1:35:26,  2.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved partial embeddings up to image 15000 → /content/drive/MyDrive/FER2013_images/partial_15000.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings:  70%|██████▉   | 20000/28709 [2:24:33<1:04:22,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved partial embeddings up to image 20000 → /content/drive/MyDrive/FER2013_images/partial_20000.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings:  87%|████████▋ | 25000/28709 [2:59:24<22:58,  2.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved partial embeddings up to image 25000 → /content/drive/MyDrive/FER2013_images/partial_25000.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings: 100%|██████████| 28709/28709 [3:21:54<00:00,  2.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved final embeddings to /content/drive/MyDrive/FER2013_images/arcface_train_embeddings.npz (28477 samples)\n",
            "📥 Resuming from partial embeddings: partial_5000.npz\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/det_500m.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\n",
            "find model: ./models/buffalo_s/w600k_mbf.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (224, 224)\n",
            "✅ Buffalo-S FaceAnalysis loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting embeddings: 100%|██████████| 2178/2178 [13:18<00:00,  2.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved final embeddings to /content/drive/MyDrive/FER2013_images/arcface_test_embeddings.npz (7133 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 6️⃣ Train classifier and evaluate on test set\n",
        "# ============================================\n",
        "clf = LogisticRegression(max_iter=2000, class_weight='balanced', solver='saga')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"📊 Test set Accuracy: {acc*100:.2f}%\")\n",
        "print(\"✅ Classifier trained and evaluated.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO_7WmDoXOmd",
        "outputId": "2f001d71-98e3-46c9-c2eb-8cac45f8bb4c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Test set Accuracy: 68.13%\n",
            "✅ Classifier trained and evaluated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}
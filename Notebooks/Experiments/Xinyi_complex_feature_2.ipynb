{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d8085ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import Adam\n",
    "import time\n",
    "from torch.utils.data import Subset\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "data_dir = \"../../fer2013\"\n",
    "num_classes = 7  # FER-2013 has 7 emotions\n",
    "batch_size = 64\n",
    "num_epochs = 15\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Data transforms ---\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet mean/std\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccf22a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Using only 20 samples per class for quick testing.\n"
     ]
    }
   ],
   "source": [
    "# --- Datasets ---\n",
    "train_dataset = datasets.ImageFolder(root=f\"{data_dir}/train\", transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(root=f\"{data_dir}/test\", transform=val_transforms)\n",
    "\n",
    "# Limit to n samples per class\n",
    "def limit_per_class(dataset, n=20):\n",
    "    \"\"\"Return a subset with up to n samples per class.\"\"\"\n",
    "    targets = [sample[1] for sample in dataset.samples]\n",
    "    selected_idx = []\n",
    "    class_counts = defaultdict(int)\n",
    "    for idx, label in enumerate(targets):\n",
    "        if class_counts[label] < n:\n",
    "            selected_idx.append(idx)\n",
    "            class_counts[label] += 1\n",
    "    return Subset(dataset, selected_idx)\n",
    "\n",
    "# --- Optional: limit dataset size for quick testing ---\n",
    "limit_samples = True   # üîπ change to True to enable limiting for testing\n",
    "samples_per_class = 20  # üîπ how many per class when enabled\n",
    "\n",
    "if limit_samples:\n",
    "    train_dataset = limit_per_class(train_dataset, samples_per_class)\n",
    "    val_dataset = limit_per_class(val_dataset, samples_per_class)\n",
    "    print(f\"‚öôÔ∏è Using only {samples_per_class} samples per class for quick testing.\")\n",
    "else:\n",
    "    print(\"‚úÖ Using full dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b8bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebf603",
   "metadata": {},
   "source": [
    "### üí° Why Replace the Classifier Head in EfficientNet-B0\n",
    "EfficientNet-B0 was pretrained on ImageNet with 1000 object categories, so its final layer outputs 1000 logits. \n",
    "\n",
    "For FER-2013, we only have 7 emotion classes (`angry, disgust, fear, happy, sad, surprise, neutral`), so we replace the classifier with `Dropout(p=0.4)` and `Linear(in_features=1280, out_features=7)`. \n",
    "\n",
    "This way, we keep the pretrained **feature extractor** (which already detects useful visual features like edges and textures) and only retrain the **final output layer** to learn how to classify emotions instead of objects.\n",
    "\n",
    "**Summary:**\n",
    "| Part | Kept or Changed | Purpose |\n",
    "|------|-----------------|----------|\n",
    "| Convolutional \"features\" | ‚úÖ Kept | Extracts general visual patterns |\n",
    "| Classifier \"head\" | üîÅ Replaced | Matches 7 emotion classes |\n",
    "| Dropout | üîß Tuned | Reduces overfitting on smaller datasets |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2dbed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyizhu/anaconda3/envs/w207/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/xinyizhu/anaconda3/envs/w207/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /Users/xinyizhu/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 71.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Model ---\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Freeze early layers (optional)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# --- Replace classifier head ---\n",
    "\n",
    "# Number of features coming from EfficientNet‚Äôs backbone (1280 for B0)\n",
    "in_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    # Dropout helps reduce overfitting since FER-2013 is relatively small\n",
    "    nn.Dropout(0.4),\n",
    "    \n",
    "    # num_classes = 7\n",
    "    nn.Linear(in_features, num_classes)\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ad57e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss & Optimizer ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3924a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n",
      "--------------------\n",
      "train Loss: 1.9832 Acc: 0.1643\n",
      "val Loss: 1.9672 Acc: 0.1500\n",
      "\n",
      "Epoch 2/15\n",
      "--------------------\n",
      "train Loss: 1.9473 Acc: 0.2000\n",
      "val Loss: 1.9607 Acc: 0.1857\n",
      "\n",
      "Epoch 3/15\n",
      "--------------------\n",
      "train Loss: 1.9665 Acc: 0.1500\n",
      "val Loss: 1.9584 Acc: 0.1786\n",
      "\n",
      "Epoch 4/15\n",
      "--------------------\n",
      "train Loss: 1.9544 Acc: 0.1357\n",
      "val Loss: 1.9565 Acc: 0.1786\n",
      "\n",
      "Epoch 5/15\n",
      "--------------------\n",
      "train Loss: 1.9507 Acc: 0.1643\n",
      "val Loss: 1.9540 Acc: 0.1500\n",
      "\n",
      "Epoch 6/15\n",
      "--------------------\n",
      "train Loss: 1.9355 Acc: 0.1786\n",
      "val Loss: 1.9483 Acc: 0.1357\n",
      "\n",
      "Epoch 7/15\n",
      "--------------------\n",
      "train Loss: 1.9241 Acc: 0.1714\n",
      "val Loss: 1.9385 Acc: 0.1571\n",
      "\n",
      "Epoch 8/15\n",
      "--------------------\n",
      "train Loss: 1.9423 Acc: 0.1786\n",
      "val Loss: 1.9349 Acc: 0.1857\n",
      "\n",
      "Epoch 9/15\n",
      "--------------------\n",
      "train Loss: 1.9695 Acc: 0.1286\n",
      "val Loss: 1.9323 Acc: 0.1929\n",
      "\n",
      "Epoch 10/15\n",
      "--------------------\n",
      "train Loss: 1.9548 Acc: 0.1643\n",
      "val Loss: 1.9325 Acc: 0.2071\n",
      "\n",
      "Epoch 11/15\n",
      "--------------------\n",
      "train Loss: 1.9629 Acc: 0.1357\n",
      "val Loss: 1.9351 Acc: 0.2143\n",
      "\n",
      "Epoch 12/15\n",
      "--------------------\n",
      "train Loss: 1.9201 Acc: 0.2214\n",
      "val Loss: 1.9373 Acc: 0.2071\n",
      "\n",
      "Epoch 13/15\n",
      "--------------------\n",
      "train Loss: 1.9174 Acc: 0.1929\n",
      "val Loss: 1.9402 Acc: 0.2143\n",
      "\n",
      "Epoch 14/15\n",
      "--------------------\n",
      "train Loss: 1.9210 Acc: 0.2143\n",
      "val Loss: 1.9405 Acc: 0.2000\n",
      "\n",
      "Epoch 15/15\n",
      "--------------------\n",
      "train Loss: 1.9506 Acc: 0.1571\n",
      "val Loss: 1.9396 Acc: 0.2000\n",
      "\n",
      "Best Validation Accuracy: 0.2143\n",
      "Training complete in 13.73 minutes.\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "def train_model(model, criterion, optimizer, num_epochs=15):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "                loader = train_loader\n",
    "            else:\n",
    "                model.eval()\n",
    "                loader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(loader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(loader.dataset)\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "            # Save best model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                torch.save(model.state_dict(), \"best_efficientnetb0_fer2013.pth\")\n",
    "\n",
    "    print(f\"\\nBest Validation Accuracy: {best_acc:.4f}\")\n",
    "    return model\n",
    "\n",
    "# --- Train ---\n",
    "start = time.time()\n",
    "model = train_model(model, criterion, optimizer, num_epochs)\n",
    "print(f\"Training complete in {(time.time() - start)/60:.2f} minutes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w207",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
